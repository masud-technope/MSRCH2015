thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
52625202,52625202,null,1,0,Wed Oct 03 10:38:00 EDT 2018,4675403,"<p>I have an IOT sensor which sends the following message to IoT MQTT Core topic:</p>		<pre><code>{"ID1":10001,"ID2":1001,"ID3":101,"ValueMax":123}	</code></pre>		<p>I have added ACT/RULE which stores the incoming message in an S3 Bucket with the timestamp as a key(each message is stored as a seperate file/row in the bucket).</p>		<p>I have only worked with SQL databases before, so having them stored like this is new to me. </p>		<p>1) Is this the proper way to work with S3 storage?</p>		<p>2) How can I visualize the values in a schema instead of separate files?</p>		<p>3) I am trying to create ML Datasource from the S3 Bucket, but get the error below when Amazon ML tries to create schema: </p>		<blockquote>	  <p>"Amazon ML can't retrieve the schema. If you've just created this	  datasource, wait a moment and try again."</p>	</blockquote>		<p>Appreciate all advice there is! </p>	"
52625202,92187912,52625202,3,0,Wed Oct 03 12:41:00 EDT 2018,1312478,"S3 storage is like your hard-drive which has files and directory structure. Why are u not putting this data into some MySQL again or might be DynamoDB.. ?"
52625202,92188006,52625202,3,0,Wed Oct 03 12:43:00 EDT 2018,4675403,"I want to create a Machine Learning Schema and it didnt support DynamoDB (also DynamoDB had a limit on 400kb, so not that much data).. S3 seemed to be standard for ML in AWS?"
52625202,92188191,52625202,3,0,Wed Oct 03 12:48:00 EDT 2018,1312478,"as i mentioned; if u want to store files (which has data in it).. S3 is solution.. but if you want to store only a small String as mentioned here; then u can save it in MongoDB or even MySQL as such.. There is no such standard which says use S3 only.. Depends on your use-case"
52625202,92188205,52625202,3,0,Wed Oct 03 12:48:00 EDT 2018,1312478,"but yes, generally people need to read lots of data in files; hence, they use s3"
52625202,92189773,52625202,3,0,Wed Oct 03 13:28:00 EDT 2018,3083468,"DynamoDB's 400kb limit is per record which isn't an issue because MQTT messages are limited to 128kb."
52625202,52636601,52625202,2,0,Wed Oct 03 22:36:00 EDT 2018,1661089,"<blockquote>	  <p>1) Is this the proper way to work with S3 storage?</p>	</blockquote>		<p>With only one sensor, using the [timestamp](<a href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-sql-functions.html#iot-function-timestamp" rel="nofollow noreferrer">https://docs.aws.amazon.com/iot/latest/developerguide/iot-sql-functions.html#iot-function-timestamp</a> function in your IoT rule would be a way to name unique objects in S3, but there are issues that might come up.</p>		<ol>	<li><p>With more than one sensor, you might have multiple messages arrive at the same timestamp and this would not generate unique object names in S3.</p></li>	<li><p>Timestamps from nearly the same time are going to have similar prefixes and designing your S3 keys this way may not give you the best performance at higher message rates.</p></li>	</ol>		<p>Since you're using MQTT, you could use the <a href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-sql-functions.html#iot-sql-function-traceid" rel="nofollow noreferrer">traceId</a> function instead of the timestamp to avoid these two issues if they come up.</p>		<blockquote>	  <p>2) How can I visualize the values in a schema instead of separate files?</p>	  	  <p>3) I am trying to create ML Datasource from the S3 Bucket, but get the error below when Amazon ML tries to create schema:</p>	</blockquote>		<p>For the third question, I think you could be running into a <a href="https://docs.aws.amazon.com/machine-learning/latest/dg/understanding-the-data-format-for-amazon-ml.html" rel="nofollow noreferrer">data format</a> problem in ML because your S3 objects contain the JSON data from your messages and not a CSV.</p>		<p>For the second question, I think you're trying to combine message data from successive messages into a CSV, or at least output the message data as a single line of a CSV file. I don't think this is possible with just the Iot SQL language since it's intended to produce JSON.</p>		<p>One alternative is to configure your IoT SQL rule with a Lambda action and use a lambda function to make your JSON to CSV conversion and then write the CSV to your S3 bucket. If you go this direction, you may have to enrich your IoT message data with the timestamp (or traceId) as you call the lambda.</p>		<p>A rule like <code>select timestamp() as timestamp, traceid() as traceid, concat(ID1, ID2, ID3, ValueMax) as values, * as message</code> would produce a JSON like</p>		<p><code>{"timestamp":1538606018066,"traceid":"abab6381-c369-4a08-931d-c08267d12947","values":[10001,1001,101,123],"message":{"ID1":10001,"ID2":1001,"ID3":101,"ValueMax":123}}</code></p>		<p>That would be straightforward to use as the source for a CSV row with the data from its values property.</p>	"
