thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
46130900,46130900,null,1,0,Sat Sep 09 12:51:00 EDT 2017,2575407,"<p>I am doing an IoT sensor based project. In this each sensor is sending data to the server in every minute. I am expecting a maximum of 100k sensors in the future.</p>		<p>I am logging the data sent by each sensor in history table. But I have a Live Information table in which latest status of each sensor is being updated. </p>		<p>So I want to update the row corresponding to each sensor in Live Table, every minute. </p>		<p>Is there any problem with this? I read that frequent update operation is bad in cassandra.</p>		<p>Is there a better way? </p>		<p>I am already using Redis in my project for storing session etc. Should I move this LIVE table to Redis?</p>	"
46130900,79228285,46130900,3,0,Sat Sep 09 16:54:00 EDT 2017,8233725,"Is it possible to use the latest inserted record in history table instead of using the separate live table for getting the current status of a particular sensor?"
46130900,79234699,46130900,3,0,Sun Sep 10 00:07:00 EDT 2017,2575407,"For that I need to store history table data in DESC order and I can fetch latest data with LIMIT 1 option. But if I do like that a lot other performance issue will come. Like if I need to get data from a start date to end date for plotting graphs, analytics etc.."
46130900,79256247,46130900,3,1,Mon Sep 11 01:53:00 EDT 2017,266337,"be sure to use leveled compaction strategy instead of default for update heavy workloads and wont be a problem"
46130900,79223857,46130900,3,0,Sat Sep 09 12:53:00 EDT 2017,1144035,"Why would you be updating?  Just insert the new data into the table."
46130900,79223884,46130900,3,0,Sat Sep 09 12:55:00 EDT 2017,2575407,"Hi, As I explained, I am already inserting data to history table.	But I have a live table. For eg. client need to see the current readings/status  of all the sensors. I am showing it from Live Table. So I need to update live table every minute when a new data is arrived."
46130900,46132618,46130900,2,0,Sat Sep 09 16:14:00 EDT 2017,6176785,"<p>At C* there's consistency levels for reading and consistency levels to write. If are going to have only one node then this not apply, zero problems, but if are going to use more than one dc or racks you need to increase the consistency level to grant that what you are retrieving is the last version of the updated row, or at writing level use an high consistency level. In my case I'm using ANY to write and QUORUM to read. This allows me to have all nodes expect one down to write and 51% up of the nodes to read. This is a trade off in the CAP theorem. Pls take a look at:</p>		<p><a href="http://docs.datastax.com/en/cassandra/latest/cassandra/dml/dmlConfigConsistency.html" rel="nofollow noreferrer">http://docs.datastax.com/en/cassandra/latest/cassandra/dml/dmlConfigConsistency.html</a></p>		<p><a href="https://wiki.apache.org/cassandra/ArchitectureOverview" rel="nofollow noreferrer">https://wiki.apache.org/cassandra/ArchitectureOverview</a></p>	"
46130900,79312145,46132618,3,0,Tue Sep 12 11:20:00 EDT 2017,6176785,"The fastest option is: create keyspace mykeyspace with replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 } AND durable_writes = false;"
46130900,46151793,46130900,2,2,Mon Sep 11 09:00:00 EDT 2017,1516699,"<p>This is what you're looking for: <a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_memtable_thruput_c.html" rel="nofollow noreferrer">https://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_memtable_thruput_c.html</a></p>		<blockquote>	  <p>How you tune memtable thresholds depends on your data and write load. Increase memtable throughput under either of these conditions:</p>	  	  <ul>	  <li><p>The write load includes a high volume of updates on a smaller set of data.</p></li>	  <li><p>A steady stream of continuous writes occurs. This action leads to more efficient compaction.</p></li>	  </ul>	</blockquote>		<p>So increasing <strong>commitlog_total_space_in_mb</strong> will make Cassandra flush memtables to disk less often. This means most of your updates will happen in memory only and you will have fewer duplicates of data. </p>	"
