thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
53309291,53309291,null,1,0,Wed Nov 14 21:54:00 EST 2018,710618,"<p>I am fairly new to Cassandra and I am trying to understand how to design my tables for IoT sensors.</p>		<p>The idea is to have several devices, each with several sensors attached to it sending data periodically (up to around 200000 values per device per day per sensor)</p>		<p>I'd like to be able to query for the latest value of a sensor for a specific list of sensors and devices in more or less real-time. Also devices do not always send data and may be down for long periods of time.</p>		<p>After a lot of reading I came up with something like this</p>		<pre><code>CREATE TABLE "sensor_data" (	    deviceid TEXT,	    sensorid TEXT,	    ts timestamp,	    value TEXT,	    PRIMARY KEY ((deviceid, sensorid), ts)	) WITH CLUSTERING ORDER BY (ts DESC);	</code></pre>		<p>The idea behind this would be to perform one query per device and sensor such as </p>		<pre><code>Select deviceid, sensorid, ts, value where deviceid = "device1" and sensorid = "temperature" limit 1	</code></pre>		<p>And run this for each device and sensor. It's not one query to return it all (Which would be ideal) but seems to be fast enough to run for potentially up to 100 sensors or so (With possibilities for parallelizing the queries) for a few devices.</p>		<p>However from what I have read so far, I understand this would give me a lot of columns for my row and it might be complicated in terms of long term storage and Cassandra limitations.</p>		<p>I am thinking that maybe adding something like the date to the table like so (as seen on some blogs and guides) might be a good idea</p>		<pre><code>CREATE TABLE "sensor_data" (	    deviceid TEXT,	    sensorid TEXT,	    date TEXT	    ts timestamp,	    value TEXT,	    PRIMARY KEY ((deviceid, sensorid, date), ts)	) WITH CLUSTERING ORDER BY (ts DESC);	</code></pre>		<p>And then query like</p>		<pre><code>Select deviceid, sensorid, date, ts, value where deviceid = "device1" and sensorid = "temperature" and date = "2018-11-14" limit 1	</code></pre>		<p>Does that even make sense? It feels like it might mitigate storage issues and allow for easier archiving of old data in the future however how do I go about querying for the latest value of a specific sensor and device if that device was down for a day or more? Do I really have to query for 1 day, if nothing is found, query the previous day and so forth (Maybe limit it to only the last few days or so)?</p>		<p>Are there better ways to handle this in Cassandra or am I in the right direction?</p>	"
53309291,53342666,53309291,2,3,Fri Nov 16 17:25:00 EST 2018,10663730,"<p>Part of the problem that you'll run into is that each sensor will be having 200k readings per day. In general, you want to keep each partition under <a href="https://docs.datastax.com/en/dse-planning/doc/planning/planningPartitionSize.html" rel="nofollow noreferrer">100k rows</a>. So, your second idea (having date as part of the PK) may have perf issues.</p>		<p>Really what you are looking to do is what we refer to as 'bucketing'; how to group things together so queries are usable and performant.</p>		<p>To really help with this, we will need to understand a little more information: </p>		<ul>	<li>How many devices do you have? Will that number grow or is it finite?</li>	<li>In plain English, what is an example of queries that you are trying to answer?</li>	</ul>		<p><strong>Incorporating this into the answer based on your answers (below):</strong></p>		<p>Alright, here is a potential idea... </p>		<p>We DO care about bucketing though to try to stay around the 100k/partition optimal rows in a partition.</p>		<p>You're going to want two tables:</p>		<ol>	<li>Lookup table</li>	<li>Sensor table</li>	</ol>		<p>Lookup table will look something like:</p>		<pre><code>CREATE TABLE lookup-table (	deviceid TEXT,	sensor-map MAP,	PRIMARY KEY (deviceid)	);	</code></pre>		<ul>	<li><code>deviceid</code> is the unique ID for each device</li>	<li><code>sensor-map</code> is a JSON <a href="https://docs.datastax.com/en/cql/3.3/cql/cql_reference/cql_data_types_c.html" rel="nofollow noreferrer">map</a> of sensors that a given device has and a corresponding unique ID for that specific sensor (e.g. {temperature: 183439, humidity : 84543292, other-sensor : blah})</li>	<li>That way each device has a mapping of sensors that is available to it</li>	<li>Example query would be: <code>SELECT * FROM lookup-table WHERE deviceid = 1234;</code></li>	<li>Another approach would be to have individual columns for each type of sensor and the unique ID for each sensor as a value</li>	</ul>		<p>Sensor table will look like:</p>		<pre><code>CREATE TABLE sensor_data (	sensorid TEXT,	sensor_value (whatever data type fits what you need),	ts TIMESTAMP,	reading_date date,	time_bucket int,	PRIMARY KEY ((reading_date, sensorid, time_bucket), ts)	) WITH CLUSTERING ORDER BY (ts DESC);	</code></pre>		<ol>	<li>As each sensor will get 200k readings/day AND we want to keep each partition under 100k rows, that means we want to do two partitions for each sensor each day</li>	<li>How could you bucket? You should do it in two parts:you need to bucket daily; each sensor gets a new partition each day (<code>reading_date</code>) and split each day into two (due to the amount of readings that you're expecting); AM or PM; AM equals bucket 1, PM equals bucket 2. Or use 24 hour time where 0-1200 equals 1, 1300-2399 equals 2</li>	<li>Within your application provide the specific <code>sensorid</code> and	<code>time_bucket</code> will come from the time that you're actually requesting	the query (e.g. if time is 1135 hours, then <code>time_bucket = 1</code>) and <code>reading_date</code> will come from the actual day that you are querying</li>	<li>Since you are clustering with <code>ts DESC</code> then it will retrieve the	latest reading for that given <code>sensorid</code>. So it would look like	<code>SELECT * from sensor_data WHERE reading_date = 12/31/2017 AND sensorid = 1234 AND time_bucket = 1 LIMIT 1;</code></li>	<li>By maintaining <code>ts</code> as a clustering column, you'll be able to keep all of the readings for a given sensor; none will be overwritten</li>	</ol>		<p><strong>Important to know</strong>: this works great if there is an even distribution of sensor readings throughout the 24-hour day. However, if you're reading heavily in the morning and not at all in the afternoon, then it isn't an even and we'll have to figure out another way to bucket. But, I think that you get what is going on. </p>		<p><strong>To query:</strong></p>		<ul>	<li>There will be one query to retrieve all of the <code>sensorid</code> that a device has; once you have those <code>sensorid</code>, you can then use it for the next step</li>	<li>There will be <em>n</em> queries for each <code>sensor_value</code> for each <code>sensorid</code></li>	<li>Since we are bucketing (via <code>time_bucket</code>), you should have an even distribution throughout all of the partitions</li>	</ul>		<p><strong>Lastly: give me the latest <code>sensorid</code> by a given value</strong>	To do that there are a couple of different ways...</p>		<ul>	<li>Run a Spark job: to do that, you'll have to lift and shift the data to run the Spark query</li>	<li>Use DataStax Enterprise: with DSE you have an integrated Analytics component based on Spark so you can run Spark jobs without having to manage a separate Spark cluster. Disclosure: I work there, btw</li>	<li>Create an additional Cassandra (C*) table and do some parallel writes</li>	</ul>		<p>For the additional C* table: </p>		<pre><code>CREATE TABLE sensor_by_value (	sensor-value INT,	ts TIMESTAMP,	sensorid TEXT,	reading_date DATE,	time_bucket INT,	PRIMARY KEY ((sensor-value, reading_date), ts)	) WITH CLUSTERING ORDER BY (ts DESC);	</code></pre>		<p>You will definitely have to do some time bucketing here: </p>		<ul>	<li>Remember, we don't want any more than 100k rows per partition</li>	<li>You'll have to understand the possible values (range)</li>	<li>The frequency of each reading</li>	<li>If you have 100 devices, 100 sensors, and each sensor being read up to 200k per day, then you have a potential for up to 2B sensor readings per day...</li>	<li>Typically, what I have my customers do is run some analysis on their data to understand these bits of info, that way you can be sure to account for it</li>	<li>How much you have to bucket will depend on the frequency</li>	<li>Good luck! :-)</li>	</ul>		<p><strong>Final tip</strong></p>		<p>Look into compaction strategies: specifically <a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/operations/opsConfigureCompaction.html" rel="nofollow noreferrer">time window compaction strategy</a> (TWCS) and adding a <code>default_time_to_live</code></p>		<ul>	<li><p>Your data seems immutable after the initial insert</p></li>	<li><p>TWCS will make the operational overhead of compaction much lower as you fine-tune it for the time window that you need</p></li>	<li><p>A <code>default_ttl</code> will also help with the operational overhead of deleting data after you don't need it anymore.</p></li>	</ul>		<p>Does this answer and/or satisfy that queries that you're trying to answer? If not, let me know and we can iterate.</p>		<p>To learn all of this stuff, go to <a href="https://academy.datastax.com" rel="nofollow noreferrer">DataStax Academy</a> for a ton of free training. Data Modeling (DS 220) is a great course!</p>	"
53309291,93665119,53342666,3,0,Tue Nov 20 14:12:00 EST 2018,710618,"I think this very much answers my question. Thank you for the time and effort put into it"
53309291,93636161,53342666,3,0,Mon Nov 19 17:59:00 EST 2018,10663730,"Do you read all sensors for a given device at the same time (e.g. exact same `ts`) and then insert them or do they come in individually?"
53309291,93602432,53342666,3,0,Sun Nov 18 16:15:00 EST 2018,10663730,"Thanks for the context. You were definitely on the right track. There are bounds though that you want to stay under to have performant queries: keep each partition under 100k rows, no partition greater than 100MB, no more than 2B columns in a partition. These are guidelines, of course, but that how you make your queries fast.		https://docs.datastax.com/en/dse/6.0/cql/cql/cql_using/cqlSyntax.html?hl=billion%2Ccells%2Cpartition	https://docs.datastax.com/en/dse-planning/doc/planning/planningPartitionSize.html		As far as some recommendations, let me get back to you shortly on that..."
53309291,93602722,53342666,3,0,Sun Nov 18 16:30:00 EST 2018,10663730,"One more question: for your second question `Find the latest reading with a value of X for a specific sensor`: what is the range of possibilities that the sensor can display? Be sure to include how many decimal points, etc. Also, do you know the distribution (roughly) in those values (e.g. there is an average and it follows a normal distribution, etc.)"
53309291,93577962,53342666,3,0,Sat Nov 17 09:46:00 EST 2018,710618,"Thank you. The main query I am looking for is "Give me the latest value for each sensor, in a list of sensors". We could be OK with limiting this query to a few days and handling the lack of a response if no value  is found for the sensor in a reasonable amount of time. Another one we struggle with (though not included in the question above) is "Find the latest reading with a value of X for a specific sensor". Those are our main queries right now. Adding the date to the PK was intended as "bucketing" as you mentioned. Maybe I misunderstood the concept?"
53309291,93578413,53342666,3,0,Sat Nov 17 10:23:00 EST 2018,710618,"Number of devices is very small to being with (Around 10) but can grow to potentially 500, maybe more. My estimate is to design this for a limit of 100 devices for now."
53309291,93612350,53342666,3,0,Mon Nov 19 03:24:00 EST 2018,10663730,"Sorry for all of the comments and questions; I am new to this and trying to help. I just updated my answer above based on your feedback."
53309291,93647511,53342666,3,0,Tue Nov 20 03:46:00 EST 2018,10663730,"Updated with more of an idea for you..."
53309291,93706637,53342666,3,0,Wed Nov 21 16:08:00 EST 2018,10663730,"Yeah, this can be a little confusing as you get started. A way to think about it is with cells instead of columns. Here is a good quick read to better understand the topic though: https://stackoverflow.com/questions/20512710/cassandra-has-a-limit-of-2-billion-cells-per-partition-but-whats-a-partition"
53309291,93706900,53342666,3,0,Wed Nov 21 16:15:00 EST 2018,10663730,"In its most simple form: we have our clustering columns (which are the number of unique rows within a partition) and regular columns (columns that are not part of the PRIMARY KEY, e.g. everything else). Number of cells = clustering columns * regular columns. Number of cells <= 2B"
53309291,93621471,53342666,3,0,Mon Nov 19 10:36:00 EST 2018,710618,"Sorry I realised my mistake in the comments. The correct query would actually be "Give me the latest value for each sensor, in a list of sensor for a specific deviceid" so you are correct in that the sensorid is no different than a sensor_type.	As the latest reading with a value of X. The range is difficult to predict but let's say I am looking for a very specific value. I am looking into potentially have the value as an UDT to support sensors with number or strings or floats and so and the idea would be to ask the a very specific value of that type"
53309291,93640125,53342666,3,0,Mon Nov 19 20:27:00 EST 2018,710618,"They come individually at their own pace. Some more often than others"
53309291,93671993,53342666,3,0,Tue Nov 20 17:30:00 EST 2018,10663730,"Awesome! Glad to hear it. I just updated the answer one last time to help point you into the right direction for answering your last query of "give me a `sensorid` based on a specific value" as well as a final tip on compaction strategy."
53309291,93699572,53342666,3,0,Wed Nov 21 12:53:00 EST 2018,710618,"Thanks. I get confused about the 2B column limit. In your example above, we would have about 4 columns right? When would one have 2B columns? That would be a huge CREATE TABLE statement. Or am I missing something?"
