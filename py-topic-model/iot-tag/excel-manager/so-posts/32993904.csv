thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
32993904,32993904,null,1,2,Wed Oct 07 13:45:00 EDT 2015,3362540,"<p>I have a stream that I would like to read from a sensor.  The stream never ends.  Most of the time the values repeat over time.  So I would like to identify runs of values and just keep the first and last of each run, and keep their timestamps too.</p>		<p>Here is an example of 10 minutes of data:</p>		<p>[['8:00', 4],['8:01', 4],['8:02', 4],['8:03', 7],['8:04', 7],['8:05', 8],['8:06', 9],['8:07', 13],['8:08', 13],['8:09', 13]].lazy </p>		<p>I want to compress this data to this:	[['8:00', 4],['8:02', 4],['8:03', 7],['8:04', 7],['8:05', 8],['8:06', 9],['8:07', 13],['8:09', 13]]</p>		<p>I've been trying to accomplish this through enumerable functions such as  chunk, each_cons, each_with_object.  This problem, though, seems inherently functional.  Can I accomplish this using lazy enumerator in ruby?</p>	"
32993904,32996079,32993904,2,0,Wed Oct 07 15:16:00 EDT 2015,802618,"<pre><code>data.reduce([data.first]) do |result, item|	  result.last.last == item.last ? result : result + [item]	end	</code></pre>		<p>This doesn't produce exactly your desired output - it skips the last item of the run. But the good news is you don't need the last item, because you know its value is the same as your first item, and you know its timestamp is one less than the next item. (If your timestamps aren't consecutive, then this is no good). If the last entry also isn't at <code>Time.now</code>, the simplest thing to do is just manually tack it on at the end.</p>		<p>What it does:</p>		<ul>	<li>Initializes the result with the first value. This is simply to avoid a <code>nil</code> case at the beginning.</li>	<li>For each <code>item</code> in <code>data</code>		<ul>	<li>If the value in <code>item.last</code> is the same as the last entry currently in <code>result</code>, do nothing</li>	<li>If the value in <code>item.last</code> is different, append it to <code>result</code></li>	</ul></li>	</ul>		<p>I've written it so that each iteration produces a new <code>result</code> array with <code>result + [item]</code>, which is the functional style and preferred way to use <code>reduce</code>, but that produces a lot of unnecessary intermediate arrays. You can create just one new array by actually appending (<code>&lt;&lt;</code>) instead.</p>	"
32993904,53904520,32996079,3,0,Fri Oct 09 15:22:00 EDT 2015,802618,"Yeah, thought that might be the case. Glad you found a way!"
32993904,53854101,32996079,3,0,Thu Oct 08 12:19:00 EDT 2015,3362540,"Your solution works as you describe, and does so elegantly.  It captures the first sample of each run of identical values, but does not capture the final sample of a run.  However I do want that ending sample.  In my example the samples come at a regular interval--one per minute--but in reality I can never enjoy that sort of predictability due to data transmission problems and sensor issues.  There will be gaps.  So it would not be possible to calculate the final time that the last sample of a run was measured."
32993904,33015513,32993904,2,0,Thu Oct 08 12:14:00 EDT 2015,2187540,"<p>That's not an elegant solution, but it works.</p>		<pre><code>data = ['8:00', 4],['8:01', 4],['8:02', 4],['8:03', 7],['8:04', 7],['8:05', 8],['8:06', 9],['8:07', 13],['8:08', 13],['8:09', 13]		def clean_array(data)	    item_to_delete = []		    (0..(data.count-3)).each do |i|	        if data[i][1].eql?(data[i+2][1])	            item_to_delete &lt;&lt; data[i+1]	        end	    end		    data - item_to_delete	end		new_data = clean_array(data)	</code></pre>		<p>The output, as expected is</p>		<pre><code>=&gt; [["8:00", 4], ["8:02", 4], ["8:03", 7], ["8:04", 7], ["8:05", 8], ["8:06", 9], ["8:07", 13], ["8:09", 13]]	</code></pre>		<p>Edit</p>		<p>Another approach</p>		<pre><code>data = ['8:00', 4],['8:01', 4],['8:02', 4],['8:03', 7],['8:04', 7],['8:05', 8],['8:06', 9],['8:07', 13],['8:08', 13],['8:09', 13]    	new_data = []		data.each { |item| (new_data[-2] and item[1].eql?(new_data[-2][1])) ? new_data[-1] = item : new_data &lt;&lt; item }		new_data		# =&gt; =&gt; [["8:00", 4], ["8:02", 4], ["8:03", 7], ["8:04", 7], ["8:05", 8], ["8:06", 9], ["8:07", 13], ["8:09", 13]]	</code></pre>	"
32993904,53888796,33015513,3,0,Fri Oct 09 08:38:00 EDT 2015,3362540,"It's an interesting approach and it is the only one that returns precisely the answer requested.  I would not have thought to delete from the array until all unneeded samples are removed.  It also would be easy to add more granular logic."
32993904,53913611,33015513,3,0,Fri Oct 09 20:09:00 EDT 2015,2187540,"check my edit for a little bit more elegant way."
32993904,33026455,32993904,2,0,Thu Oct 08 21:43:00 EDT 2015,3362540,"<p>I am posting a solution to my own question.  I started with Kristj√°n's solution which used reduce.  Note that my solution fails to produce the final sample time, but I am choosing to accept this behavior because my example was just meant to be a simulated stream.  So that 8:09 sample is not meant to be the final value.  The next incoming sample will determine whether that 8:09 value gets stored.  So that detail of my original post could have been better explained.  </p>		<pre><code>samples = [['8:00', 4],['8:01', 4],['8:02', 4],['8:03', 7],['8:04', 7],['8:05', 8],['8:06', 9],['8:07', 13],['8:08', 13],['8:09', 13]].lazy		prev = []	compressed = samples.reduce([samples.first]) do |keepers, sample|	  keepers &lt;&lt; prev &lt;&lt; sample if keepers.last.last != sample.last	  prev = sample	  keepers	end	puts compressed.inspect		# =&gt; [["8:00", 4], ["8:02", 4], ["8:03", 7], ["8:04", 7], ["8:05", 8], ["8:05", 8], ["8:06", 9], ["8:06", 9], ["8:07", 13]]	</code></pre>	"
