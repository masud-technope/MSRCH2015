thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
44716773,44716773,null,1,0,Fri Jun 23 08:35:00 EDT 2017,8204056,"<p>I am trying to design an <code>IoT</code> platform using the above mentioned technologies. I would be happy if someone can comment on the architecture, if its good and scalable !</p>		<p>I get <code>IoT</code> sensor data through <code>mqtt</code> which I will receive through spark streaming( There is a mqtt connector for spark streaming which does it). I only have to subscribe to the topics and there is a third party server which publishes <code>IoT</code> data to the topic. </p>		<p>Then I parse the data , and insert in AWS DynamoDB . Yes whole setup will run on AWS. </p>		<p>I may have to process/transform the data in future depending on the <code>IoT</code> use cases so I thought spark might be useful . Also I have heard spark streaming is blazing fast. </p>		<p>It's a simple overview and I am not sure if its a good architecture. Will it be a overkill to use spark streaming ? Are there other ways to directly store data on DynamoDB received from <code>mqtt</code> ?</p>	"
44716773,44731507,44716773,2,0,Sat Jun 24 00:12:00 EDT 2017,1175633,"<p>I cannot state whether your components will result in a scalable architecture, since you did not elaborate on how you will scale them, nor what will be the estimated load that such a system should handle, or if there will be peaks in terms of load.</p>		<p>If you are talking about scalability in terms of <em>performance</em>, you should also consider scalability in terms of <em>pricing</em> which may be important to your project.</p>		<p>For instance, <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html" rel="nofollow noreferrer"><code>DynamoDB</code></a> is a very scalable NoSQL database service, which offers elastic performances with a very efficient pricing. I do not know much about <code>Apache Spark</code>, and even if it has been designed to be very efficient at scale, how will you distribute incoming data ? Will you host multiple instances on EC2 and use autoscaling to manage instances ?</p>		<p>My advice would be to segregate your needs in terms of components to conduct a successful analysis. To summarize your statements:</p>		<ul>	<li>You need to ingest incoming sensor telemetry at scale using MQTT.</li>	<li>You need to transform or enrich these data on the fly.</li>	<li>You need to insert these data (probably as time-series) into <code>DynamoDB</code> in order to build an <a href="https://martinfowler.com/eaaDev/EventSourcing.html" rel="nofollow noreferrer">event-sourcing system</a>.</li>	<li>Since you mentioned Apache Spark, I imagine you would need to perform some analysis of these data, either in near real-time, or in batch, to build value out of your data.</li>	</ul>		<p>My advice would be to use serverless, managed services in AWS so that you can only pay for what really you use, and forget about the maintenance, or the scalability, and focus on your project.</p>		<ul>	<li><a href="https://aws.amazon.com/iot/" rel="nofollow noreferrer">AWS IoT</a> is a platform built into AWS which will allow you to <strong>securely</strong> ingest data at <strong>any scale</strong> using MQTT.</li>	<li>This platform also embeds a <a href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-rules.html" rel="nofollow noreferrer">rules engine</a>, which will allow you to build your business rules in the cloud. For example, intercepting incoming messages, enrich them, and call other AWS services as a result (e.g calling a <a href="https://docs.aws.amazon.com/lambda/latest/dg/welcome.html" rel="nofollow noreferrer">Lambda function</a> to do some processing on the ingested data).</li>	<li>The rules engine has a native connector to <code>DynamoDB</code>, which will allow you to insert your enriched or transformed data into a table.</li>	<li>The rules engine has also a connector to the new <a href="https://aws.amazon.com/machine-learning/" rel="nofollow noreferrer">Amazon Machine Learning</a> service, if you want to get predictions on sensor data in real-time.</li>	<li>You can then use other services such as <a href="https://aws.amazon.com/emr/details/spark/?nc1=h_ls" rel="nofollow noreferrer">EMR + Spark</a> to batch-process your data once a day, week, month.</li>	</ul>		<p>The advantage here is that you assemble your components and use them as you go, meaning that you do not need the full featured stack when you are beginning, but still have the flexibility of making changes in the future.</p>		<hr>		<p>An overview of the AWS IoT service.</p>		<p><a href="https://i.stack.imgur.com/7Aosp.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/7Aosp.png" alt="enter image description here"></a></p>	"
44716773,76489682,44731507,3,0,Mon Jun 26 06:59:00 EDT 2017,8204056,"main thing is the cost. At this point in time I am unable to estimate the cost. And it may be lame but in future if I want to port or maintain my own IoT platform , its easier if I have less dependency. You think this won't be an option ? https://www.nginx.com/blog/nginx-plus-iot-load-balancing-mqtt/"
44716773,76525670,44731507,3,0,Tue Jun 27 05:09:00 EDT 2017,8204056,"This is a low power wan based IoT setup with a target of 100k devices sending messages every minute ( or less), raw data size would be about 100 bytes. Plan is to host our application on AWS and use DynamoDB + lambda (still evaluating) and hope for a better cost margin."
44716773,76525943,44731507,3,0,Tue Jun 27 05:24:00 EDT 2017,1175633,"Ok, thanks for your response, interesting, so you implement something using a network akin to LoraWan if I understand correctly. Is it critical for devices to send a message every minute, especially for low power devices ? Can't it be less often, when something changes on the device, or a few times a day ?"
44716773,76526090,44731507,3,0,Tue Jun 27 05:32:00 EDT 2017,8204056,"Yes , its based on LoRa and its not necessary to send messages every minute, but I considered the extreme scenario. Message size is very small as you might have guessed already. Some devices may be getting continuous power so they can send messages any number of times per day."
44716773,76487232,44731507,3,0,Mon Jun 26 04:32:00 EDT 2017,8204056,"Thanks for your elaborate answer @Halim . I don't want to use AWS IoT due to some constraints. Coming back to the scalability thing, I am looking for various options like nginx /shared mqtt to handle the incoming requests which could be about 15-20k msgs/second. And I will use DynamoDB lambda feature to trigger action on the data which is inserted into the DynamoDb by spark streaming application."
44716773,76489158,44731507,3,0,Mon Jun 26 06:36:00 EDT 2017,1175633,"@Gurubg do you want to elaborate on your constraints regarding AWS IoT ? Maybe we can find a solution. Regarding other options, I would look at HiveMQ since it can support clustering, and gives you the ability to handle large, variable, loads of incoming messages. But that is pretty much reimplementing what AWS has done with its IoT service. Hence my question ;)"
44716773,76522043,44731507,3,0,Tue Jun 27 00:40:00 EDT 2017,1175633,"This *can* be an option, along with a distributed MQTT cluster. But you'll have to administer this system yourself, handle faults, errors, maintenance, hence still having to depend on it. Also may I ask for which type of application, and with how many concurrent devices you expect to have 20k messages/second coming in ?"
44716773,76554796,44731507,3,0,Tue Jun 27 18:06:00 EDT 2017,1175633,"If it is just one way, an idea would be to use serverless services within AWS to handle the message (S3 which is *very* cost-efficient, or API Gateway + DynamoDB). This would relieve you of having to maintain a complete MQTT cluster. Now another question arises, how do you handle authentication, and authorization of the embedded devices. Do they have embedded certificates, or some sort of credentials ?"
44716773,76526197,44731507,3,0,Tue Jun 27 05:38:00 EDT 2017,1175633,"Two more questions, do you require bi-directional communication between your cloud platform and the Lora gateways, or is uni-directional communication acceptable? And do you need to process ingested data in real-time, or batch-processing them once or twice a day would be sufficient ?"
44716773,76586187,44731507,3,0,Wed Jun 28 12:58:00 EDT 2017,8204056,"Is it ideal to write data received from sensors into S3 as files ? Later I can use EMR spark to perform analytics if needed ? But I am afraid there will be too many files on S3 ! Can you some light on how its done usually ?"
44716773,76538650,44731507,3,0,Tue Jun 27 11:28:00 EDT 2017,8204056,"I am happy to answer your questions, its just one way from lora side to our platform , data ingested will be processed in real time and push notifications are triggered to the mobile apps . Depending on the use cases we may also have to query for a certain set of data and analyse it ."
44716773,76572674,44731507,3,0,Wed Jun 28 07:28:00 EDT 2017,1175633,"You can make SQL queries to your S3 buckets using AWS Athena. But not really adapted to real-time streams. API Gateway and DDB, could be a solution. You can also push data into Kinesis, make real-time queries in sliding windows, anomaly detection, etc, and then persist data into DynamoDB or S3 later on. I would compare these solutions in terms of performance for my detailed use-case, and in terms of cost (typically, price per device)."
44716773,76571810,44731507,3,0,Wed Jun 28 07:04:00 EDT 2017,8204056,"Authentication is done by third party , device data is not directly received by our platform. There is one more layer in between which is not handled by us which will take care of authentication, security etc. Our platform will subscribe to this third party provided mqtt topic using SSL ! if I use S3 I can not query on that data right ?"
44716773,76592141,44731507,3,0,Wed Jun 28 14:58:00 EDT 2017,1175633,"Usually data go through a kinesis stream which can store device telemetry and run SQL queries on a sliding or tumbling window to analyse th√© data in real-time. In parallel you can ask kinesis to store received telemetry after having buffered it for some time (e.g 5 minutes). So there will be less objects creation on S3, and each object consists of a collection of telemetry data for x minutes."
