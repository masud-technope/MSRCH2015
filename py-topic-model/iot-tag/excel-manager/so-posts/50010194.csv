thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
50010194,50010194,null,1,0,Tue Apr 24 20:22:00 EDT 2018,2900948,"<p>I have a very simple table to log reading from sensors. There's a column for sensor id number, one for sensor reading and one for the timestamp. This column is of SQL type Timestamp. There's a big amount of data in the table, a few million rows.</p>		<p>When I query for all rows before a certain timestamp with a certain sensor id number, sometimes it can take a very long time. If the timestamp is far in the past, the query is pretty fast but, if it's a recent timestamp, it can take up to 2 or 3 seconds.</p>		<p>It appears as if the SQL engine is iterating over the table until it finds the first timestamp that's larger than the queried timestamp. Or maybe the larger amount of queried data slows it down, I don't know.</p>		<p>In any case, I'm looking for design suggestions here, specifically to address to points: why is it so slow? and how can I make it faster?</p>		<p>Is there any design technique that could be applied here? I don't know much about SQL, maybe there's a way to let the SQL engine know the data is ordered (right now it's not but I could order it upon insertion I guess) and speed up the query. Maybe I should change the way the query is done or change the data type of the timestamp column.</p>	"
50010194,87037358,50010194,3,0,Tue Apr 24 20:36:00 EDT 2018,2548147,""If the timestamp is far in the past, the query is pretty fast but, if it's a recent timestamp, it can take up to 2 or 3 seconds." -> You might want to upgrade to MySQL 8.0 which supports DESC on indexes might speed up the searches on recent timestamps.."
50010194,87037434,50010194,3,0,Tue Apr 24 20:39:00 EDT 2018,2548147,""It appears as if the SQL engine is iterating over the table until it finds the first timestamp that's larger than the queried timestamp. Or maybe the larger amount of queried data slows it down, I don't know." provide `EXPLAIN [query]` for a query in the past and a query with a recent timestamp so we can see if the plans are different."
50010194,50010325,50010194,2,0,Tue Apr 24 20:32:00 EDT 2018,107744,"<p>Use <code>EXPLAIN</code> to see the execution plan, and verify that the query is using a suitable index. If not, verify that appropriate indexes are available.</p>		<p>An <code>INDEX</code> is stored "in order", and MySQL can make effective of use with some query patterns. (An InnoDB table is also stored in order, by the cluster key, which is the PRIMARY KEY of the table (if it exists) or the first UNIQUE KEY on non-NULL columns.)</p>		<p>With some query patterns, by using an index, MySQL can eliminate vast swaths of rows from being examined. When MySQL can't make user of an index (either because a suitable index doesn't exist, or because the query has constructs that prevent it), the execution plan is going to do a full scan, that is, examine <em>every</em> row in the table. And when that happens with very large tables, there's a tendency for things to get slow.</p>		<p><strong>EDIT</strong></p>		<p>Q: Why is it so slow?</p>		<p>A: There are several factors that affect the elapsed time. It could be contention, for example, an exclusive table lock taken by another session, or it could be time for I/O (disk reads), or a large "Using filesort" operation. Time for returning resultset over a slow network connection. </p>		<p>It's not possible to diagnose the issue with the limited information provided. We can only provide some suggestions about some common issue. </p>		<p>Q: How can I make it faster?</p>		<p>A: It's not possible to make a specific recommendation. We need to figure out where and what the bottleneck is, and the address that. </p>		<p>Take a look at the output from <code>EXPLAIN</code> to examine the execution plan. Is an appropriate index being used, or is it doing a full scan? How many rows are being examined? Is there "Using filesort" operation? et al.</p>		<p>Q: Is there any design technique that could be applied here?</p>		<p>A: In general, having an appropriate index available, and carefully crafting the SQL statement so the most efficient access plan is enabled.</p>		<p>Q: Maybe I should change the way the query is done </p>		<p>A: Changing the SQL statement may improve performance, that's a good place to start, after looking at the execution plan... can the query be modified to get a more efficient plan? </p>		<p>Q: or change the data type of the timestamp column.</p>		<p>A: I think it's very unlikely that changing the datatype of the TIMESTAMP column will improve performance. That's only 4 bytes. What would you change it to?  Using <code>DATETIME</code> would take 7 bytes.</p>		<p>In general, we want the rows to be as short as possible, and to pack as many rows as possible into a block. Its also desirable to have the table physically organized in a way that queries can be satisfied from fewer blocks... the rows the query need are found in fewer pages, rather than the rows being scattered onesy-twosy over a large number of pages.</p>		<p>With InnoDB, increasing the size of the buffer pool may reduce I/O.</p>		<p>And I/O from solid state drives (SSD) will be faster than I/O from spinning hard disks (HDD), and this especially true if there is I/O contention on the HDD from other processes.</p>	"
50010194,87041675,50010325,3,0,Wed Apr 25 01:08:00 EDT 2018,2548147,"True using a index that has a good unique selectivity or the so called cardinality in MySQL would on large datasets outperform a full table scan.. â€œI think I was careful in my answer to not make any claim that an execution plan using an index is always better (or faster) than a full table scan.â€? i think i jumped when i read â€œthe execution plan is going to do a full scan, that is, examine every row in the table. And when that happens with large tables, things are gonna get slow.â€?"
50010194,87039430,50010325,3,0,Tue Apr 24 22:19:00 EDT 2018,107744,"@RaymondNijland; True. With *large* sets, full scans do tend to be expensive (and slow) as compared to a plan using index seek for query with predicate `some_unique_indexed_col = some_val`. I attempted to make it clear (in my answer) that we are talking about some *specific* query patterns (*particular* SQL constructs) that can take advantage of *suitable* indexes. I think I was careful in my answer to *not* make any claim that an execution plan using an index is always better (or faster) than a full table scan. But given OP vague description of performance, and no mention of any index ..."
50010194,87039531,50010325,3,0,Tue Apr 24 22:26:00 EDT 2018,107744,"... I suspect that the table OP is querying doesn't have *any* index defined on it, and the query is doing a full scan. That's just conjecture, since we don't see any table or index definition, we don't know if the table is InnoDB, and we don't see any SQL query text, we can't make a specific recommendation. We can recommend using `EXPLAIN` to see the execution plan (which might lead OP to take a look at the MySQL Reference Manual), and to at least mention the possible performance benefits of an appropriate index."
50010194,87037864,50010325,3,0,Tue Apr 24 20:58:00 EDT 2018,2548147,"a table scan isn't per definion slow but it depends on your table size, query, indexing and ofcource disk hardware.. In fact in some cases using a index (multiple random disk i/o) might be more costly then to use a full table scan (one random disk i/o).. Then the MySQL optimizer will then have a preference to do a FULL table scan instead."
