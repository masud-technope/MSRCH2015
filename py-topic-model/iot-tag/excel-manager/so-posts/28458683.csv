thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
28458683,28458683,null,1,1,Wed Feb 11 15:54:00 EST 2015,3863920,"<p>I read through azure documentation and found that the message size limit of Queues is 64 Kb and Service Bus is 256 KB. We are trying to develop an application  which will read sensor data from the some devices, call a REST Service  and upload it to cloud . This data will be stored in the queues and then dumped in to a Cloud database.</p>		<p>There could be chances that the sensor data collected is more than 256 KB... In such cases what is the recommended approach... Do we need to split the data	in the REST service and then put chunks of data in the queue or is there any other recommended pattern</p>		<p>Any help is appreciated</p>	"
28458683,54690790,28458683,3,0,Sat Oct 31 13:23:00 EDT 2015,3005995,"If you found my answer useful, please mark as answer."
28458683,45250615,28458683,3,0,Wed Feb 11 19:06:00 EST 2015,3863920,"I  need to run analytics on that data in  future... You mean put it in blob store and store a reference in queue , so that the worker process can read it and save it to DB"
28458683,45266448,28458683,3,0,Thu Feb 12 06:48:00 EST 2015,3863920,"Thanks a lot  for your suugestions"
28458683,45244471,28458683,3,0,Wed Feb 11 16:16:00 EST 2015,188096,"You can put the data in blob storage always whether or not its size is more than 256KB."
28458683,45260084,28458683,3,1,Thu Feb 12 00:37:00 EST 2015,188096,"That's right. You store the data in blob storage and then create a message with blob URL and store in the queue. Your worker process can fetch messages from the queue, get the blob URL, read and process the data."
28458683,33437605,28458683,2,3,Fri Oct 30 13:49:00 EDT 2015,3005995,"<p>You have several conflicting technology statements.  I will begin by clarifying a few.</p>		<ol>	<li><p>Service Bus/IoT Hub are not post calls.  A post call would use a	restful service, which exists separately.  IoT Hub uses a low	latency message passing system that is abstracted from you.  These	are intended to be high volume small packets and fits most IoT	scenarios.</p></li>	<li><p>In the situation in which a message is larger than 256 KB (which is very interesting for an IoT scenario, I would be interested to	see why those messages are so large), you should ideally upload to	blob storage.  You can still post packets</p>		<ul>	<li>If you have access to blob storage api's with your devices, you should go that route</li>	<li><p>If you do not have access to this, you should post big packets to a rest endpoint and cross your fingers it makes it or chop it up.</p>		<ol start="3">	<li>You can run post analytics on blob storage, I would recommend using the wasb prefix as those containers are Hadoop compliant and you can stand up analytics clusters on top of those storage mechanisms.</li>	</ol></li>	</ul></li>	</ol>		<p>You have no real need for a queue that I can immediately see.  </p>		<p>You should take a look at the patterns leveraging:</p>		<ol>	<li>Stream Analytics: <a href="https://azure.microsoft.com/en-us/services/stream-analytics/" rel="nofollow">https://azure.microsoft.com/en-us/services/stream-analytics/</a> </li>	<li>Azure Data Factory: <a href="https://azure.microsoft.com/en-us/services/data-factory/" rel="nofollow">https://azure.microsoft.com/en-us/services/data-factory/</a> </li>	</ol>		<p>Your typical ingestion will be:  Get your data up into the cloud into super cheap storage as easily as possible and then deal with analytics later using clusters you can stand up and tear down on demand.  That cheap storage is typically blob and that analytics cluster is usually some form of Hadoop.  Using data factory allows you to pipe your data around as you figure out what you are going to use specific components of it for.</p>		<p>Example of having used HBase as ingestion with cheap blob storage as the underlayment and Azure Machine Learning as part of my analytics solution: <a href="http://indiedevspot.com/2015/07/09/powering-azureml-with-hadoop-hbase/" rel="nofollow">http://indiedevspot.com/2015/07/09/powering-azureml-with-hadoop-hbase/</a> </p>	"
