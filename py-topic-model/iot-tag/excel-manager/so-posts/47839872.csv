thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
47839872,47839872,null,1,2,Fri Dec 15 21:08:00 EST 2017,2706419,"<p>I'm using Heron for performing streaming analytics on IoT data. Currently in the architecture there is only one spout with parallelism factor 1.</p>		<p>I'm trying to benchmark the stats on the amount of data Heron can hold in the queue which it internally uses at spout.</p>		<p>I'm playing around with the method setMaxSpoutPending() by passing value to it. I want to know if there is any limit on the number which we pass to this method?</p>		<p>Can we tweak the parameter method by increasing system configuration or providing more resource to the topology?</p>	"
47839872,83043542,47839872,3,0,Sat Dec 30 18:30:00 EST 2017,8845188,"Are you sure this should be tagged as a Storm/Spark question? It seems specifically about Heron."
47839872,83061430,47839872,3,0,Sun Dec 31 19:25:00 EST 2017,2706419,"@StigRohdeDÃ¸ssing But I couldn't find Heron tag while adding the question :("
47839872,83172896,47839872,3,0,Thu Jan 04 15:57:00 EST 2018,8845188,"Sorry, I think you're right and there doesn't seem to be a Heron tag. I was just a little confused about why this was tagged as a Storm question :)"
47839872,47876709,47839872,2,1,Mon Dec 18 21:32:00 EST 2017,9018004,"<p>So if you have one spout and one bolt, then max spout pending is the best way to control the number of pending tuples.	Max Spout pending can be increased indefinitely. However increasing it beyond a certain amount increases the probability of timeout errors happening and in the worst case there could be no forward progress. Also higher msp typically require more heap required for spout and other components of the topology.</p>	"
47839872,82719246,47876709,3,0,Mon Dec 18 21:40:00 EST 2017,2070111,"Your response is more about seeking clarification than giving an actual answer to the problem. It would be better done as a comment to the question."
47839872,82759091,47876709,3,0,Tue Dec 19 22:30:00 EST 2017,2706419,"@Sanjeev I'm receiving encoded data(temperature) in spout and passing it on to a bolt in the topology to compute the moving average on the decoded data(temperature). I'm doing some benchmarking on the data the spout can handle in flight. So that we can tweak the resource allocation to the topology and see if something changes"
47839872,48099416,47839872,2,1,Thu Jan 04 16:23:00 EST 2018,9090512,"<p>MSP is used to control the topology ingestion rate; it tells Storm the maximum number of tuples that may be unacknowledged at any given time. If the MSP is lower than the parallelism of the topology, it can be a bottle neck.  On the other hand, increasing MSP beyond the topology parallelism level can lead to the topology being 'flooded' and unable to keep up with the inbound tuples.  In such a situation the 'message timeout' of the topology will be exceeded and Storm will attempt to replay them while still feeding new tuples.  Storm will stop feeding new inbound tuples only when the MSP limit is reached.</p>		<p>So yes, you can tweak it but keep an eye out for increasing timed out tuples indicating that your topology is overwhelmed.</p>		<p>BTW, if you're processing IoT events you may be able to increase parallelism by grouping the spout tuples by the device id (tuple stream per device) using field grouping.</p>	"
