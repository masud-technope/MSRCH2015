thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
39817430,39817430,null,1,1,Sun Oct 02 13:17:00 EDT 2016,4824279,"<p>I'm looking for a distributed Time series database which is free to use in a cluster setup up mode and production ready plus it has to fit well in the hadoop ecosystem.</p>		<p>I have an IOT project which is basically around 150k Sensors which send data every 10 minutes or One hour, so I'm trying to look at time series database that has useful functions like aggregating metrics, Down-sampling, pre-aggregate (roll-ups) i have found this comparative in this Google stylesheet document <a href="https://docs.google.com/spreadsheets/d/1sMQe9oOKhMhIVw9WmuCEWdPtAoccJ4a-IuZv4fXDHxM/edit#gid=1102272647" rel="nofollow">time series database comparative</a> .</p>		<p>I have tested Opentsdb, the data model of the hbaserowkey really suits my use case :  but the functions that sill need to be developed for my use case are :</p>		<ul>	<li>aggregate multiples metrics </li>	<li>do rollups </li>	</ul>		<p>I have tested also keirosDB which is a fork of opentsdb with a richer API and it uses Cassandra as a backend storage the thing is that their API does all what my looking for downsampling rollups querying multiples metrics and a lot more.</p>		<p>I have tested Warp10.io and Apache Phoenix which i have read here <a href="http://hortonworks.com/blog/hood-ambari-metrics-grafana/" rel="nofollow">Hortonworks link</a> that it will be used by Ambari Metrics so i assume that its well suited for time series data too.</p>		<p>My question is as of now what's the best Time series Database to do real time analytics with requests performance under 1S for all the type of requests example : we want the average of the aggregated data sent by 50 sensors in a period of 5 years resampled by months ?</p>		<p>Such requests I assume can't be done under 1S so I believe for such requests we need some rollups/ pre aggregate  mechanism, but I'm not so sure because there's a lot of tools out there and i can't decide which one suits my need the best.</p>	"
39817430,40191604,39817430,2,5,Sat Oct 22 11:31:00 EDT 2016,2657957,"<p>I'm the lead for Warp 10 so my answer can be considered opinionated.</p>		<p>Given your projected data volume, 150k sensors sending data every 10 minutes, it is a mean of 250 datapoints per second and less than 40B on a period of 5 years. Such a volume can easily fit on a simple Warp 10 standalone, and if you later need to have a larger infrastructure you can migrate to a distributed Warp 10 based on Hadoop.</p>		<p>In terms of requests, if your data is already resampled, fetch 5 years of monthly data for 50 sensors is only 3000 datapoints, Warp 10 can do that in far less than 1s, and doing the automatic rollups is just a matter of scheduling WarpScript code in a monthly manner, nothing fancy.</p>		<p>Lastly, in terms of integration with the Hadoop ecosystem, Warp 10 is on top of things with integration of the WarpScript language in Pig, Spark, Flink and Storm. With the Warp10InputFormat you can fetch data from a Warp 10 platform or you can load data using any other InputFormat and then manipulate them using WarpScript.</p>	"
39817430,46098966,39817430,2,0,Thu Sep 07 14:30:00 EDT 2017,1842308,"<p>At OVH we are heavy users of @OvhMetrics which rely on Warp10/HBase, and we provide a protocol abstraction with OpenTSDB/WarpScript/PromQL/... </p>		<p>I'm not interested in Warp10, but it has been a great success for us. Both on the scaling challenge and for the use cases that WarpScript can cover.</p>		<p>Most of the time we don't even leverage hadoop/flink integration because our customers needs are addressed easily with the real time WarpScript API.</p>	"
39817430,57427321,39817430,2,0,Fri Aug 09 09:38:00 EDT 2019,10328430,"<p>For real time analytics, you can try <a href="https://druid.apache.org/" rel="nofollow noreferrer">Druid</a>, an open source project maintainted by Apache, or you can also check out database specialized for IoT: <a href="https://griddb.net/en/" rel="nofollow noreferrer">GridDB</a> and <a href="https://crate.io/" rel="nofollow noreferrer">CrateDB</a>. The best way is to test these databases yourselves and see if they suit your need. You can also connect these databases as a sink to Kafka. </p>		<p>When you are dealing with IoT project, you need to forecast if you have to maintain large data set in the future or if you are happy with downsampled data. Some TSDB have good compression like InfluxDB, but others may not be scalable beyond tens of terabytes, so if you think you need to scale big, look also for one with scale-out architecture. </p>	"
