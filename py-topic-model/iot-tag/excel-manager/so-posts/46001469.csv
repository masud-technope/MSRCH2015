thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
46001469,46001469,null,1,1,Fri Sep 01 13:37:00 EDT 2017,7723121,"<p>I have a large variable data set between 50MB to 1GB to be sent to cloud services AWS/ AZURE etc from MCU based systems in a single request on a daily basis. As far as I know the cost associated to send such large amount of data to AWS IOT/ AZURE would be extremely high for a small company as they consider a single packet equivalent to 512kb of data.</p>		<p>I'm looking for suggestions as to what could be my alternatives - whether using simple cloud database (like digitalocean etc) be cost efficient for me. But then if I use non IOT specific cloud services then how could I send my data from MCU upto database.</p>	"
46001469,46002433,46001469,2,0,Fri Sep 01 14:27:00 EDT 2017,13070,"<p>This seems to be a very common problem with IoT. You're going to need to use a non-IoT service to send those larger pieces of data to the cloud. Sticking with AWS I would recommend something like the following:</p>		<p>Send an MQTT message requesting temporary AWS IAM credentials to an AWS IoT topic configured to trigger a Lambda function. The Lambda function would call the AWS STS service to obtain temporary credentials with the needed permissions, and then send those to an MQTT topic that the IoT device is subscribed to. Once the IoT device gets the temporary credentials it could use those to upload the larger files to an S3 bucket. Another Lambda function could be triggered by the files arriving in S3, at which point it could do any processing needed and insert the data into a database or something.</p>		<p>You could skip the disjointed request/response model of using MQTT topics to request and receive the temporary credentials, and instead hit an API Gateway endpoint that calls the Lambda function and returns the STS credentials, however that would require you to have some sort of extra API credentials configured on your IoT device, like an API key at the very least.</p>	"
46001469,78969740,46002433,3,0,Fri Sep 01 16:25:00 EDT 2017,7723121,"Thanks for a prompt response Mark. I still have a few doubts about the same:-	1) Wouldn't the above method lead a large monthly expense since the number of MQTT publishing request to server would be too large for a daily data of around 1GB + the S3 and dynamodb storage fee charged by aws would be separate?	2)I'm not even sure whether sending such a large data over a single MQTT request recommended or feasable?	3) Wouldn't it be better if I use some other cloud storage provider and push the data via REST calls from WINC1500 type of hardware?"
46001469,78969815,46002433,3,0,Fri Sep 01 16:28:00 EDT 2017,13070,"I don't think you understood my answer. You would only send a request for credentials, and receive a small credentials packet, over MQTT. The actual files would be uploaded directly to S3, not MQTT."
46001469,78970055,46002433,3,0,Fri Sep 01 16:36:00 EDT 2017,7723121,"Got it! Appreciate your help on this Mark. Thanks"
