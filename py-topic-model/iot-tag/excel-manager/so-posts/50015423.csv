thread_ID, Id, ParentId, PostType, Score, CreationDate, OwnerID, Body
50015423,50015423,null,1,2,Wed Apr 25 06:30:00 EDT 2018,5966481,"<p>Currently we are migrating our IoT platform as a PAAS service. We are using HDInsight Hbase for all IoT data insertion. Now i am able to create and delete tables in the HBase from java application. But i am not able insert or select any data from the HDInight Hbase table. Please suggest me if anything is missing in code level.</p>		<p>HBase Insert Java Code:</p>		<pre><code>// TODO Auto-generated method stub	   // define some people	 Configuration config = HBaseConfiguration.create();		 // Example of setting zookeeper values for HDInsight	 // in code instead of an hbase-site.xml file	 //	  config.set("hbase.zookeeper.quorum",	             "zk1:2181,zk2:2181,zk3:2181");	 config.set("hbase.zookeeper.property.clientPort", "2181");	 config.set("hbase.cluster.distributed", "true");	 //	 //NOTE: Actual zookeeper host names can be found using Ambari:	 //curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts"		 //Linux-based HDInsight clusters use /hbase-unsecure as the znode parent	 config.set("zookeeper.znode.parent","/hbase-unsecure");	 System.out.println("1 - " + config);	 String[][] people = {	     { "1", "Marcel", "Haddad", "marcel@fabrikam.com"},	     { "2", "Franklin", "Holtz", "franklin@contoso.com" },	     { "3", "Dwayne", "McKee", "dwayne@fabrikam.com" },	     { "4", "Rae", "Schroeder", "rae@contoso.com" },	     { "5", "Rosalie", "burton", "rosalie@fabrikam.com"},	     { "6", "Gabriela", "Ingram", "gabriela@contoso.com"} };		 HTable table = new HTable(config, "people");	 System.out.println("2 - " + table);	 // Add each person to the table	 //   Use the `name` column family for the name	 //   Use the `contactinfo` column family for the email	 for (int i = 0; i&lt; people.length; i++) {	     Put person = new Put(Bytes.toBytes(people[i][0]));	     person.add(Bytes.toBytes("name"), Bytes.toBytes("first"), Bytes.toBytes(people[i][1]));	     person.add(Bytes.toBytes("name"), Bytes.toBytes("last"), Bytes.toBytes(people[i][2]));	     person.add(Bytes.toBytes("contactinfo"), Bytes.toBytes("email"), Bytes.toBytes(people[i][3]));	     System.out.println("3 - " + person);	     table.put(person);	     System.out.println("4 - " + table);	 }	 // flush commits and close the table	 System.out.println("5 - " + table);	 table.flushCommits();	 table.close();	 System.out.println("6 - " + table);	</code></pre>		<p>Error : </p>		<pre><code>2083 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x524d6d96 connecting to ZooKeeper ensemble=zk0-bdtrin.un52sso10ikejkjuhwkxemgbfa.rx.internal.cloudapp.net:2181,zk4-bdtrin.un52sso10ikejkjuhwkxemgbfa.rx.internal.cloudapp.net:2181,zk1-bdtrin.un52sso10ikejkjuhwkxemgbfa.rx.internal.cloudapp.net:2181	7616 [main] WARN  o.a.h.c.Configuration - hbase-site.xml:an attempt to override final parameter: dfs.support.append;  Ignoring.	7616 [main] WARN  o.a.h.h.u.DynamicClassLoader - Failed to identify the fs of dir /hbase/lib, ignored	java.io.IOException: No FileSystem for scheme: wasb	      at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2584) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2591) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:354) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.1.jar:?]	      at org.apache.hadoop.hbase.util.DynamicClassLoader.&lt;init&gt;(DynamicClassLoader.java:104) [hbase-common-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.protobuf.ProtobufUtil.&lt;clinit&gt;(ProtobufUtil.java:238) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.ClusterId.parseFrom(ClusterId.java:64) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:75) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:879) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.&lt;init&gt;(ConnectionManager.java:635) [hbase-client-1.1.0.jar:1.1.0]	      at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_151]	      at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) [?:1.8.0_151]	      at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [?:1.8.0_151]	      at java.lang.reflect.Constructor.newInstance(Constructor.java:423) [?:1.8.0_151]	      at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.ConnectionManager.createConnection(ConnectionManager.java:420) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.ConnectionManager.createConnectionInternal(ConnectionManager.java:329) [hbase-client-1.1.0.jar:1.1.0]	      at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:144) [hbase-client-1.1.0.jar:1.1.0]	      at com.trinity.iot.storm.topology.HbaseTest.main(HbaseTest.java:34) [classes/:?]	7697 [main] WARN  o.a.h.c.Configuration - hbase-site.xml:an attempt to override final parameter: dfs.support.append;  Ignoring.	7750 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x2d0399f4 connecting to ZooKeeper ensemble=zk1:2181,zk2:2181,zk3:2181	</code></pre>		<p>hbase-site.xml</p>		<pre><code> &lt;configuration&gt;		    &lt;property&gt;	      &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;	      &lt;value&gt;/var/lib/hadoop-hdfs/dn_socket&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;dfs.support.append&lt;/name&gt;	      &lt;value&gt;false&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.bucketcache.combinedcache.enabled&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.bucketcache.ioengine&lt;/name&gt;	      &lt;value&gt;file:/mnt/hbase/cache.data&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.bucketcache.percentage.in.combinedcache&lt;/name&gt;	      &lt;value&gt;&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.bucketcache.size&lt;/name&gt;	      &lt;value&gt;81920&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.bulkload.staging.dir&lt;/name&gt;	      &lt;value&gt;/apps/hbase/staging&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.client.keyvalue.maxsize&lt;/name&gt;	      &lt;value&gt;1048576&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.client.retries.number&lt;/name&gt;	      &lt;value&gt;35&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.client.scanner.caching&lt;/name&gt;	      &lt;value&gt;100&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt;	      &lt;value&gt;&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;	      &lt;value&gt;org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.custom-extensions.root&lt;/name&gt;	      &lt;value&gt;/hdp/ext/2.6/hbase&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.defaults.for.version.skip&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.fs.shutdown.hook.wait&lt;/name&gt;	      &lt;value&gt;600000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.majorcompaction&lt;/name&gt;	      &lt;value&gt;0&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.majorcompaction.jitter&lt;/name&gt;	      &lt;value&gt;0.50&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt;	      &lt;value&gt;10737418240&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.memstore.block.multiplier&lt;/name&gt;	      &lt;value&gt;4&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;	      &lt;value&gt;134217728&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hregion.memstore.mslab.enabled&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hstore.blockingStoreFiles&lt;/name&gt;	      &lt;value&gt;100&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hstore.compaction.max&lt;/name&gt;	      &lt;value&gt;10&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hstore.compaction.max.size&lt;/name&gt;	      &lt;value&gt;32212254720&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.hstore.compactionThreshold&lt;/name&gt;	      &lt;value&gt;3&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.local.dir&lt;/name&gt;	      &lt;value&gt;${hbase.tmp.dir}/local&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.distributed.log.splitting&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.info.bindAddress&lt;/name&gt;	      &lt;value&gt;0.0.0.0&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.info.port&lt;/name&gt;	      &lt;value&gt;16010&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.namespace.init.timeout&lt;/name&gt;	      &lt;value&gt;2400000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.port&lt;/name&gt;	      &lt;value&gt;16000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.ui.readonly&lt;/name&gt;	      &lt;value&gt;false&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.master.wait.on.regionservers.timeout&lt;/name&gt;	      &lt;value&gt;30000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.region.server.rpc.scheduler.factory.class&lt;/name&gt;	      &lt;value&gt;org.apache.hadoop.hbase.ipc.PhoenixRpcSchedulerFactory&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.executor.openregion.threads&lt;/name&gt;	      &lt;value&gt;20&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.global.memstore.size&lt;/name&gt;	      &lt;value&gt;0.4&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;	      &lt;value&gt;100&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.hlog.blocksize&lt;/name&gt;	      &lt;value&gt;134217728&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.info.port&lt;/name&gt;	      &lt;value&gt;16030&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.optionalcacheflushinterval&lt;/name&gt;	      &lt;value&gt;7200000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.port&lt;/name&gt;	      &lt;value&gt;16020&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt;	      &lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.rest.port&lt;/name&gt;	      &lt;value&gt;8090&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.rootdir&lt;/name&gt;	      &lt;value&gt;/hbase&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.rpc.protection&lt;/name&gt;	      &lt;value&gt;authentication&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.rpc.timeout&lt;/name&gt;	      &lt;value&gt;90000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.rs.cacheblocksonwrite&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.security.authentication&lt;/name&gt;	      &lt;value&gt;simple&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.security.authorization&lt;/name&gt;	      &lt;value&gt;false&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.shutdown.hook&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.superuser&lt;/name&gt;	      &lt;value&gt;hbase&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.tmp.dir&lt;/name&gt;	      &lt;value&gt;/tmp/hbase-${user.name}&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;	      &lt;value&gt;2181&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;	      &lt;value&gt;zk01,zk2,zk3&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hbase.zookeeper.useMulti&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hfile.block.cache.size&lt;/name&gt;	      &lt;value&gt;0.40&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;hfile.index.block.max.size&lt;/name&gt;	      &lt;value&gt;131072&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;io.storefile.bloom.block.size&lt;/name&gt;	      &lt;value&gt;131072&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;phoenix.functions.allowUserDefinedFunctions&lt;/name&gt;	      &lt;value&gt;true&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;phoenix.query.timeoutMs&lt;/name&gt;	      &lt;value&gt;60000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;zookeeper.recovery.retry&lt;/name&gt;	      &lt;value&gt;6&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;	      &lt;value&gt;120000&lt;/value&gt;	    &lt;/property&gt;		    &lt;property&gt;	      &lt;name&gt;zookeeper.znode.parent&lt;/name&gt;	      &lt;value&gt;/hbase-unsecure&lt;/value&gt;	    &lt;/property&gt;		  &lt;/configuration&gt;	</code></pre>		<p>pom.xml:</p>		<pre><code>&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;	  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;	  &lt;groupId&gt;HDInsight-HbaseTest&lt;/groupId&gt;	  &lt;artifactId&gt;HDInsight-HbaseTest&lt;/artifactId&gt;	  &lt;version&gt;1&lt;/version&gt;	  &lt;name&gt;HDInsight-HbaseTest&lt;/name&gt;	  &lt;description&gt;HDInsight-HbaseTest&lt;/description&gt;		  &lt;dependencies&gt;	   &lt;dependency&gt;	     &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;	     &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;	     &lt;version&gt;1.1.2&lt;/version&gt;	 &lt;/dependency&gt;	 &lt;dependency&gt;	     &lt;groupId&gt;org.apache.phoenix&lt;/groupId&gt;	     &lt;artifactId&gt;phoenix-core&lt;/artifactId&gt;	     &lt;version&gt;4.4.0-HBase-1.1&lt;/version&gt;	 &lt;/dependency&gt;	 &lt;!-- https://mvnrepository.com/artifact/jdk.tools/jdk.tools --&gt;	        &lt;dependency&gt;	            &lt;groupId&gt;jdk.tools&lt;/groupId&gt;	            &lt;artifactId&gt;jdk.tools&lt;/artifactId&gt;	            &lt;version&gt;1.8.0_151&lt;/version&gt;	            &lt;scope&gt;system&lt;/scope&gt;	            &lt;systemPath&gt;${JAVA_HOME}/lib/tools.jar&lt;/systemPath&gt;	        &lt;/dependency&gt;	  &lt;/dependencies&gt;		   &lt;build&gt;	    &lt;!--  &lt;sourceDirectory&gt;src&lt;/sourceDirectory&gt; --&gt;	     &lt;resources&gt;	     &lt;resource&gt;	         &lt;directory&gt;src/main/resources&lt;/directory&gt;	         &lt;filtering&gt;false&lt;/filtering&gt;	         &lt;includes&gt;	         &lt;include&gt;hbase-site.xml&lt;/include&gt;	         &lt;/includes&gt;	     &lt;/resource&gt;	     &lt;/resources&gt;	     &lt;plugins&gt;	     &lt;plugin&gt;	         &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;	         &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;	                 &lt;version&gt;3.3&lt;/version&gt;	         &lt;configuration&gt;	             &lt;source&gt;1.8&lt;/source&gt;	             &lt;target&gt;1.8&lt;/target&gt;	         &lt;/configuration&gt;	         &lt;/plugin&gt;	     &lt;plugin&gt;	         &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;	         &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;	         &lt;version&gt;2.3&lt;/version&gt;	         &lt;configuration&gt;	         &lt;transformers&gt;	             &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ApacheLicenseResourceTransformer"&gt;	             &lt;/transformer&gt;	         &lt;/transformers&gt;	         &lt;/configuration&gt;	         &lt;executions&gt;	         &lt;execution&gt;	             &lt;phase&gt;package&lt;/phase&gt;	             &lt;goals&gt;	             &lt;goal&gt;shade&lt;/goal&gt;	             &lt;/goals&gt;	         &lt;/execution&gt;	         &lt;/executions&gt;	     &lt;/plugin&gt;	     &lt;/plugins&gt;	 &lt;/build&gt;	&lt;/project&gt;	</code></pre>	"
50015423,87090985,50015423,3,1,Thu Apr 26 07:43:00 EDT 2018,3860596,"may be you are missing some hdfs jars in your classpath"
50015423,87472012,50015423,3,0,Tue May 08 06:41:00 EDT 2018,5966481,"Thanks mbvxi for reply.. i have added the hadoop jars and working fine now."
50015423,50111001,50015423,2,0,Tue May 01 03:29:00 EDT 2018,5522534,"<p>Can you try giving FQDN for zookeeper quorum? </p>		<p>Config.set("hbase.zookeeper.quorum",	             "<strong>zk1:2181,zk2:2181,zk3:2181"</strong>);</p>	"
